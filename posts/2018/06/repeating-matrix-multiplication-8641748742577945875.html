<html><body><article class="markdown-body entry-content"><p>I watched the Hennessy &amp; Patterson's Turing award lecture recently:</p>



<p>In it, there's a slide comparing the performance of various matrix
multiplication implementations, using Python (presumably CPython) as a baseline
and comparing that against various C implementations (I couldn't find the
linked paper yet):</p>

<a href="https://1.bp.blogspot.com/-Jy_op9XTgH0/Wyo4IWrqNoI/AAAAAAAAh3w/bVrxPRSCHtY3AB8ITqe-QsqBYWCsGY7cQCPcBGAYYCw/s1600/matmul.png"><img border="0" height="360" src="https://1.bp.blogspot.com/-Jy_op9XTgH0/Wyo4IWrqNoI/AAAAAAAAh3w/bVrxPRSCHtY3AB8ITqe-QsqBYWCsGY7cQCPcBGAYYCw/s640/matmul.png" width="640"></a>

<p>I expected the baseline speedup of switching from CPython to C to be
higher and I also wanted to know what performance PyPy gets, so I did my own
benchmarks. This is a problem that Python is completely unsuited for, so it
should give very exaggerated results.</p>
<p>The usual <strong>disclaimers</strong> apply: All benchmarks are lies, benchmarking of
synthetic workloads even more so. My implementation is really naive (though I
did optimize it a little bit to help CPython), don't use any
of this <a href="https://gist.github.com/cfbolz/caa8299ebd5ab4e1203be1614a64bb54">code</a>
for anything real. The benchmarks ran on my rather old Intel i5-3230M laptop
under Ubuntu 17.10.</p>
<p>With that said, my results were as follows:</p>
<table>
<thead>
<tr>
<th>Implementation</th>
<th align="right">time</th>
<th align="right">speedup over CPython</th>
<th align="right">speedup over PyPy</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPython</td>
<td align="right">512.588 ± 2.362 s</td>
<td align="right">1 ×</td>
<td align="right"></td>
</tr>
<tr>
<td>PyPy</td>
<td align="right">8.167 ± 0.007 s</td>
<td align="right">62.761 ±  0.295 ×</td>
<td align="right">1 ×</td>
</tr>
<tr>
<td>'naive' C</td>
<td align="right">2.164 ± 0.025 s</td>
<td align="right">236.817 ±  2.918 ×</td>
<td align="right">3.773 ± 0.044 ×</td>
</tr>
<tr>
<td>NumPy</td>
<td align="right">0.171 ± 0.002 s</td>
<td align="right">2992.286 ± 42.308 ×</td>
<td align="right">47.678 ± 0.634 ×</td>
</tr></tbody></table>
<p>This is running 1500x1500 matrix multiplications with (the same) random matrices. Every
implementation is run 50 times in a fresh process. The results are averaged,
the errors are bootstrapped 99% confidence intervals.</p>
<p>So indeed the speedup that I got of switching from CPython to C is quite a bit higher than
47x! PyPy is much better than CPython, but of course can't really compete
against GCC. And then the real professionals (numpy/OpenBLAS) are in a whole
'nother league. The speedup of the AVX numbers in the slide above is even
higher than my NumPy numbers, which I assume is the result of my old CPU with
two cores, vs. the 18 core CPU with AVX support.
Lesson confirmed: leave matrix multiplication to people who
actually know what they are doing.</p>
</article></body></html>