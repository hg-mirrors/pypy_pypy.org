<html><body><p>In the last months, I've actively worked on the CLI backend for PyPy's
JIT generator, whose goal is to automatically generate JIT compilers
that produces .NET bytecode on the fly.</p>
<p>The CLI JIT backend is far from be completed and there is still a lot
of work to be done before it can handle the full PyPy's Python
interpreter; nevertheless, yesterday I finally got the first .NET
executable that contains a JIT for a very simple toy language called
<a class="reference" href="http://codespeak.net/svn/pypy/dist/pypy/jit/tl/tlr.py">tlr</a>, which implements an interpreter for a minimal register based
virtual machine with only 8 operations.</p>
<p>To compile the tlr VM, follow these steps:</p>
<blockquote>
<ol class="arabic">
<li><p class="first">get a fresh checkout of the <a class="reference" href="http://codespeak.net/svn/pypy/branch/oo-jit/">oo-jit branch</a>, i.e. the branch
where the CLI JIT development goes on:</p>
<pre class="literal-block">
$ svn co http://codespeak.net/svn/pypy/branch/oo-jit
</pre>
</li>
<li><p class="first">go to the <tt class="docutils literal"><span class="pre">oo-jit/pypy/jit/tl</span> <span class="pre">directory</span></tt>, and compile the tlr VM
with the CLI backend and JIT enabled:</p>
<pre class="literal-block">
$ cd oo-jit/pypy/jit/tl/
$ ../../translator/goal/translate.py -b cli --jit --batch targettlr
</pre>
</li>
</ol>
</blockquote>
<p>The goal of our test program is to compute the square of a given
number; since the only operations supported by the VM are addition and
negation, we compute the result by doing repetitive additions; I won't
describe the exact meaning of all the tlr bytecodes here, as they are
quite self-documenting:</p>
<pre class="literal-block">
ALLOCATE,    3,   # make space for three registers
MOV_A_R,     0,   # i = a
MOV_A_R,     1,   # copy of 'a'

SET_A,       0,
MOV_A_R,     2,   # res = 0

# 10:
SET_A,       1,
NEG_A,
ADD_R_TO_A,  0,
MOV_A_R,     0,   # i--

MOV_R_A,     2,
ADD_R_TO_A,  1,
MOV_A_R,     2,   # res += a

MOV_R_A,     0,
JUMP_IF_A,  10,   # if i!=0: goto 10

MOV_R_A,     2,
RETURN_A          # return res
</pre>
<p>You can find the program also at the end of the <a class="reference" href="http://codespeak.net/svn/pypy/dist/pypy/jit/tl/tlr.py">tlr</a> module; to get an
assembled version of the bytecode, ready to be interpreted, run this
command:</p>
<pre class="literal-block">
$ python tlr.py assemble &gt; square.tlr
</pre>
<p>Now, we are ready to execute the code through the tlr VM; if you are
using Linux/Mono, you can simply execute the <tt class="docutils literal"><span class="pre">targettlr-cli</span></tt> script
that has been created for you; however, if you use Windows, you have
to manually fish the executable inside the <tt class="docutils literal"><span class="pre">targettlr-cli-data</span></tt>
directory:</p>
<pre class="literal-block">
# Linux
$ ./targettlr-cli square.tlr 16
256

# Windows
&gt; targettlr-cli-data\main.exe square.tlr 16
256
</pre>
<p>Cool, our program computed the result correctly! But, how can we be
sure that it really JIT compiled our code instead of interpreting it?
To inspect the code that it's generated by our JIT compiler, we simply
set the <tt class="docutils literal"><span class="pre">PYPYJITLOG</span></tt> environment variable to a filename, so that the
JIT will create a .NET assembly containing all the code that has been
generated by the JIT:</p>
<pre class="literal-block">
$ PYPYJITLOG=generated.dll ./targettlr-cli square.tlr 16
256
$ file generated.dll
generated.dll: MS-DOS executable PE  for MS Windows (DLL) (console) Intel 80386 32-bit
</pre>
<p>Now, we can inspect the DLL with any IL disassembler, such as
<tt class="docutils literal"><span class="pre">ilasm</span></tt> or <tt class="docutils literal"><span class="pre">monodis</span></tt>; here is an excerpt of the disassembled code,
that shows how our <tt class="docutils literal"><span class="pre">square.tlr</span></tt> bytecode has been compiled to .NET
bytecode:</p>
<pre class="literal-block">
.method public static  hidebysig default int32 invoke (object[] A_0, int32 A_1)  cil managed
{
    .maxstack 3
    .locals init (int32 V_0, int32 V_1, int32 V_2, int32 V_3, int32 V_4, int32 V_5)

    ldc.i4 -1
    ldarg.1
    add
    stloc.1
    ldc.i4 0
    ldarg.1
    add
    stloc.2
    IL_0010:  ldloc.1
    ldc.i4.0
    cgt.un
    stloc.3
    ldloc.3
    brfalse IL_003b

    ldc.i4 -1
    ldloc.1
    add
    stloc.s 4
    ldloc.2
    ldarg.1
    add
    stloc.s 5
    ldloc.s 5
    stloc.2
    ldloc.s 4
    stloc.1
    ldarg.1
    starg 1

    nop
    nop
    br IL_0010

    IL_003b:  ldloc.2
    stloc.0
    br IL_0042

    ldloc.0
    ret
}
</pre>
<p>If you know a bit IL, you can see that the code generated is not
optimal, as there are some redundant operations like all those
stloc/ldloc pairs; however, while not optimal, it is still quite good
code, not much different to what you would get by writing the square
algorithm directly in e.g. C#.</p>
<p>As I said before, all of this is still work in progress and there is
still much to be done. Stay tuned :-).</p></body></html>