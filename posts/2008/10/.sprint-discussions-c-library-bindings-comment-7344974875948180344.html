<html><body><p>I've done a fair amount of complicated Boost.Python wrapping, and also implemented a small replacement for it with most of the complexity removed.  There are two main reasons why Boost.Python is so complicated:<br><br>1. It supports arbitrarily complex memory and sharing semantics on the C++ classes (and is runtime polymorphic on how the memory of wrapped objects is managed).<br><br>2. It supports arbitrary overloading of C++ functions.<br><br>If you remove those two generality requirements (by requiring that wrapped C++ objects are also PyObjects and banning overloading), it's possible to write very lightweight C++ bindings.  Therefore, I think it's critical to factor the C/C++ API design so that as much of it as possible is writable in application level python on top of a small core that does the final C++ dispatch.<br><br>For example, if you wrap a C++ vector class with a bunch of overloads of operator+ in Boost.Python, each call to __add__ has to do a runtime search through all the overloads asking whether each one matches the arguments passed.  Each such check does a runtime search through a table of converters.  It would a terrible shame if that overhead isn't stripped by the JIT, which means it has to be in python.<br><br>I think a good test library for thinking about these issues is numpy, since it has some memory management complexity as well as internal overloading.<br><br>I could go on, but it'd probably be better to do that via email. :)<br><br>Geoffrey</p></body></html>