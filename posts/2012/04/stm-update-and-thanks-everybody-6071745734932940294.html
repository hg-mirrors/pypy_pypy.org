<html><body><p>A short update on the Software Transactional Memory (STM) side.  Let me remind you that the work is to add STM internally into PyPy, with the goal of letting the user's programs run on multiple cores after a minor adaptation.  (The goal is not to expose STM to the user's program.)  I will soon write some official documentation that explains in more details exactly what you get.  For now you can read the previous <a class="reference" href="http://morepypy.blogspot.com/2012/03/call-for-donations-for-software.html">blog</a> <a class="reference" href="http://morepypy.blogspot.com/2012/01/transactional-memory-ii.html">posts</a>, and you can also find technical details in the <a class="reference" href="http://pypy.org/tmdonate.html">call for donation</a> itself; or directly look at how I adapted the examples linked to later in this post.</p><p>I have now reached the point where the basics seem to work.  There is no integration with the JIT so far; moreover the integration with the Garbage Collection subsystem is not finished right now, but at least it is "not crashing in my simple tests and not leaking memory too quickly". (It means that it is never calling <tt class="docutils literal"><span class="pre">__del__</span></tt> so far, although it releases memory; and when entering transactional mode or when going to the next transaction, all live objects become immortal.  This should still let most not-too-long-running programs work.)</p><p>If you want to play with it, you can download <a class="reference" href="http://wyvern.cs.uni-duesseldorf.de/~arigo/pypy-stm-22fccf3c9b5e.tar.bz2">this binary</a> (you need to put it in a place with the paths <tt class="docutils literal"><span class="pre">lib-python</span></tt> and <tt class="docutils literal"><span class="pre">lib_pypy</span></tt>, for example inside the main directory from a regular <a class="reference" href="http://buildbot.pypy.org/nightly/trunk/">nightly tarball</a> or from a full checkout). This version was compiled for Linux x86 32-bit from the <a class="reference" href="https://bitbucket.org/pypy/pypy/src/stm-gc">stm-gc</a> branch on the 25th of April.  It runs e.g. the modified version of <a class="reference" href="https://bitbucket.org/pypy/pypy/raw/stm-gc/pypy/translator/stm/test/richards.py">richards</a>. This branch could also be translated for Linux x86-64, but not for other OSes nor other CPUs for now.</p><p>The resulting <tt class="docutils literal"><span class="pre">pypy-stm</span></tt> exposes the same interface as the pure Python <a class="reference" href="https://bitbucket.org/pypy/pypy/raw/stm-gc/lib_pypy/transaction.py">transaction</a> module, which is an emulator (running on CPython or any version of PyPy) which can be used to play around and prepare your programs.  See the comments in there.  A difference is that the real <tt class="docutils literal"><span class="pre">pypy-stm</span></tt> doesn't support epoll right now, so it cannot be used yet to play with <a class="reference" href="svn://svn.twistedmatrix.com/svn/Twisted/branches/stm-5526">a branch of Twisted</a> that was already adapted (thanks Jean-Paul Calderone); but that's coming soon.  For now you can use it to get multi-core usage on purely computational programs.</p><p>I did for example adapt PyPy's own <tt class="docutils literal"><span class="pre">translate.py</span></tt>: see the tweak <a class="reference" href="https://bitbucket.org/pypy/pypy/src/stm-gc/pypy/rpython/rtyper.py#cl-249">in rpython/rtyper.py</a>.  Lines 273-281 are all that I needed to add, and they are mostly a "simplification and parallelization" of the lines above.  There are a few more places in the whole <tt class="docutils literal"><span class="pre">translate.py</span></tt> that could be similarly modified, but overall it is just that: a few places. I did not measure performance, but I checked that it is capable of using multiple cores in the RTyping step of translation, with --- as expected --- some still-reasonable number of conflicts, particularly at the beginning when shared data structures are still being built.</p><p>On a few smaller, more regular examples like <a class="reference" href="https://bitbucket.org/pypy/pypy/raw/stm-gc/pypy/translator/stm/test/richards.py">richards</a>, I did measure the performance.  It is not great, even taking into account that it has no JIT so far.  Running pypy-stm with one thread is roughly 5 times slower than running a regular PyPy with no JIT (it used to be better in previous versions, but they didn't have any GC; nevertheless, I need to investigate).  However, it does seem to scale.  At least, it scales roughly as expected on my 2-real-cores, 4-hyperthreaded-cores laptop (i.e. for N between 1 and 4, the N-threaded pypy-stm performs similarly to N independent pypy-stm's running one thread each).</p><p>And finally...</p><p>...a big thank you to everyone who contributed some money to support this!  As you see on the <a class="reference" href="http://pypy.org/">PyPy</a> site, we got more than 6700$ so far in only 5 or 6 weeks.  Thanks to that, my contract started last Monday, and I am now paid a small salary via the <a class="reference" href="http://sfconservancy.org/">Software Freedom Conservancy</a> (thanks Bradley M. Kuhn for organizational support from the SFC). Again, thank you everybody!</p><p><b>UPDATE:</b> The performance regression was due to disabling an optimization, the <i>method cache,</i> which caused non-deterministic results --- the performance could vary from simple to double.  Today, as a workaround, I made the method cache transaction-local for now; it is only effective for transactions that run for long enough (maybe 0.1ms or 1ms), but at least it is there in this situation.  In the version of richards presented above, the transactions are too short to make a difference (around 0.015ms).<br>
</p></body></html>