<html><body><p>@Benjamin: a user program might be optimized to reduce its memory usage, for example by carefully reusing objects instead of throwing them away, finding more memory-efficient constructs, and so on.  But in many cases in Python you don't care too much.  Similarly, I expect that it's possible to reduce the size of transactions by splitting them up carefully, hoping to get some extras in performance.  But most importantly I'd like a system where the programmer didn't have to care overmuch about that.  It should still work reasonably well for *any* size, just like a reasonable GC should work for any heap size.<br><br>If I had to describe the main issue I have against HTM, it is that beyond some transaction size we loose all parallelism because it has to fall back on the GIL.<br><br>Well, now that I think about it, it's the same in memory usage: if you grow past the RAM size, the program is suddenly swapping, and performance becomes terrible.  But RAM sizes are so far much more generous than maximum hardware transaction sizes.</p></body></html>