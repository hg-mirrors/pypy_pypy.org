<html><body><p><i>Hi all,</i></p>

<p><i>The <a href="http://pypy.org/tmdonate.html">Software Transactional Memory
call for donations</a> is up.  From the proposal:</i></p>

<table><tr><td width="4%"></td><td>
Previous attempts on Hardware Transactional Memory focused on parallelizing existing programs written using the <code>thread</code> or <code>threading</code> modules. However, as argued <a href="http://mail.python.org/pipermail/pypy-dev/2012-January/009044.html">here</a>, this may not be the most practical way to achieve real multithreading; it seems that better alternatives would offer good scalability too. Notably, Transactional Memory could benefit any event-based system that is written to dispatch events serially (Twisted-based, most GUI toolkit, Stackless, gevent, and so on). The events would internally be processed in parallel, while maintaining the illusion of serial execution, with all the corresponding benefits of safety. This should be possible with minimal changes to the event dispatchers. This approach has been described by the Automatic Mutual Exclusion work at Microsoft Research, but not been implemented anywhere (to the best of our knowledge).
<br><br>
Note that, yes, this gives you both sides of the coin: you keep using your non-thread-based program (without worrying about locks and their drawbacks like deadlocks, races, and friends), and your programs benefit from all your cores.
<br><br>
In more details, a low-level built-in module will provide the basics to start transactions in parallel; but this module will be only used internally in a tweaked version of, say, a Twisted reactor. Using this reactor will be enough for your existing Twisted-based programs to actually run on multiple cores. You, as a developer of the Twisted-based program, have only to care about improving the parallelizability of your program (e.g. by splitting time-consuming transactions into several parts; the exact rules will be published in detail once they are known).
</td><td width="4%"></td></tr></table>

<p><i>The point is that your program is always <i>correct</i>, and can be tweaked to improve performance.  This is the opposite from what explicit threads and locks give you, which is a performant program which you need to tweak to remove bugs.  Arguably, this approach is the reason for why you use Python in the first place :-)</i></p>

<p><i>Armin</i></p></body></html>