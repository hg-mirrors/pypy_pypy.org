<html><body><p>I have a program using Python and Twisted where I load tested both server and client connections (the program can do both the server and client protocol). I tested both types out to 100 connections (at 50 milli-second polling intervals) while measuring CPU load. <br><br>What I found was that when acting as a server it scaled fairly linearly. When acting as the client side however, load rose to a peak about 60 clients, then fell by a third until 80 clients, and then rose again until at 100 clients it reached the same load level as at 60. If you have a similar situation you may need to watch out for this phenomenon. <br><br>I also found that using the epoll reactor on Linux made a *big* difference to capacity in my applications, much more so than any normal program optimization efforts that I made. I have multiple clients and multiple server ports all running simultaneously, so I'm not sure how this may translate to your application if you are only using Twisted as a server. <br><br>Here's a link to my project web site where I show the connections versus CPU load chart (first chart):<br><br>http://mblogic.sourceforge.net/mblogichelp/general/Capacity-en.html<br><br>I haven't tested this with PyPy as I don't have a combination of anything that is both 32-bit *and* new enough to run a recent version.</p></body></html>