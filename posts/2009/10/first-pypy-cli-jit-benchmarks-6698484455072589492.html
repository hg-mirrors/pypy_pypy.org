<html><body><p>As the readers of this blog <a class="reference external" href="http://morepypy.blogspot.com/2008/11/porting-jit-to-cli-part-1.html">already know</a>, I've been working on porting the
JIT to CLI/.NET for the last months.  Now that it's finally possible to get a
working pypy-cli-jit, it's time to do some benchmarks.</p>
<p><strong>Warning:</strong> as usual, all of this has to be considered to be a alpha version:
don't be surprised if you get a crash when trying to run pypy-cli-jit.  Of
course, things are improving very quickly so it should become more and more
stable as days pass.</p>
<p>For this time, I decided to run four benchmarks. Note that for all of them we
run the main function once in advance, to let the JIT recoginizing the hot
loops and emitting the corresponding code.  Thus, the results reported do
<strong>not</strong> include the time spent by the JIT compiler itself, but give a good
measure of how good is the code generated by the JIT.  At this point in time,
I know that the CLI JIT backend spends way too much time compiling stuff, but
this issue will be fixed soon.</p>
<blockquote>
<ul class="simple">
<li><a class="reference external" href="http://paste.pocoo.org/show/145050/">f1.py</a>: this is the classic PyPy JIT benchmark. It is just a function
that does some computational intensive work with integers.</li>
<li><a class="reference external" href="http://paste.pocoo.org/show/143243/">floatdemo.py</a>: this is the same benchmark involving floating point
numbers that have already been described in a previous <a class="reference external" href="http://morepypy.blogspot.com/2009/10/pypys-jit-now-supports-floats.html">blog post</a>.</li>
<li><a class="reference external" href="http://paste.pocoo.org/show/145051/">oodemo.py</a>: this is just a microbenchmark doing object oriented stuff
such as method calls and attribute access.</li>
<li><a class="reference external" href="http://paste.pocoo.org/show/145052/">richards2.py</a>: a modified version of the classic richards.py, with a
warmup call before starting the real benchmark.</li>
</ul>
</blockquote>
<p>The benchmarks were run on a Windows machine with an Intel Pentium Dual Core
E5200 2.5GHz and 2GB RAM, both with .NET (CLR 2.0) and Mono 2.4.2.3.</p>
<p>Because of a known <a class="reference external" href="https://bugzilla.novell.com/show_bug.cgi?id=474718">mono bug</a>, if you use a version older than 2.1 you need
to pass the option <tt class="docutils literal"><span class="pre">-O=-branch</span></tt> to mono when running pypy-cli-jit, else it
will just loop forever.</p>
<p>For comparison, we also run the same benchmarks with IronPython 2.0.1 and
IronPython 2.6rc1.  Note that IronPython 2.6rc1 does not work with mono.</p>
<p>So, here are the results (expressed in seconds) with Microsoft CLR:</p>
<blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="15%">
<col width="20%">
<col width="15%">
<col width="12%">
<col width="20%">
<col width="18%">
</colgroup>
<thead valign="bottom">
<tr><th class="head">Benchmark</th>
<th class="head">pypy-cli-jit</th>
<th class="head">ipy 2.0.1</th>
<th class="head">ipy 2.6</th>
<th class="head">ipy2.01/ pypy</th>
<th class="head">ipy2.6/ pypy</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>f1</td>
<td>0.028</td>
<td>0.145</td>
<td>0.136</td>
<td>5.18x</td>
<td>4.85x</td>
</tr>
<tr><td>floatdemo</td>
<td>0.671</td>
<td>0.765</td>
<td>0.812</td>
<td>1.14x</td>
<td>1.21x</td>
</tr>
<tr><td>oodemo</td>
<td>1.25</td>
<td>4.278</td>
<td>3.816</td>
<td>3.42x</td>
<td>3.05x</td>
</tr>
<tr><td>richards2</td>
<td>1228</td>
<td>442</td>
<td>670</td>
<td>0.36x</td>
<td>0.54x</td>
</tr>
</tbody>
</table>
</blockquote>
<p>And with Mono:</p>
<blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="21%">
<col width="29%">
<col width="21%">
<col width="29%">
</colgroup>
<thead valign="bottom">
<tr><th class="head">Benchmark</th>
<th class="head">pypy-cli-jit</th>
<th class="head">ipy 2.0.1</th>
<th class="head">ipy2.01/ pypy</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>f1</td>
<td>0.042</td>
<td>0.695</td>
<td>16.54x</td>
</tr>
<tr><td>floatdemo</td>
<td>0.781</td>
<td>1.218</td>
<td>1.55x</td>
</tr>
<tr><td>oodemo</td>
<td>1.703</td>
<td>9.501</td>
<td>5.31x</td>
</tr>
<tr><td>richards2</td>
<td>720</td>
<td>862</td>
<td>1.20x</td>
</tr>
</tbody>
</table>
</blockquote>
<p>These results are very interesting: under the CLR, we are between 5x faster
and 3x slower than IronPython 2.0.1, and between 4.8x faster and 1.8x slower
than IronPython 2.6.  On the other hand, on mono we are consistently faster
than IronPython, up to 16x.  Also, it is also interesting to note that
pypy-cli runs faster on CLR than mono for all benchmarks except richards2.</p>
<p>I've not investigated yet, but I think that the culprit is the terrible
behaviour of tail calls on CLR: as I already wrote in <a class="reference external" href="http://morepypy.blogspot.com/2008/12/porting-jit-to-cli-part-3.html">another blog post</a>,
tail calls are ~10x slower than normal calls on CLR, while being only ~2x
slower than normal calls on mono.  richads2 is probably the benchmark that
makes most use of tail calls, thus explaining why we have a much better result
on mono than CLR.</p>
<p>The next step is probably to find an alternative implementation that does not
use tail calls: this probably will also improve the time spent by the JIT
compiler itself, which is not reported in the numbers above but that so far it
is surely too high to be acceptable. Stay tuned.</p></body></html>